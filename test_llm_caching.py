#!/usr/bin/env python3
"""
Test script for LLM response caching functionality.

This script tests:
1. Message hashing consistency
2. AgentOutput serialization/deserialization
3. Cache storage and retrieval
4. Integration with the Agent class
"""

import asyncio
import tempfile
import shutil
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock

# Import the modules we need to test
from browser_use.agent.cache_utils import (
    hash_messages, 
    serialize_agent_output, 
    deserialize_agent_output,
    LLMResponseCache
)
from browser_use.llm.messages import UserMessage, SystemMessage, AssistantMessage
from browser_use.agent.views import AgentOutput, ActionModel


def test_message_hashing():
    """Test that message hashing is deterministic and consistent."""
    print("üß™ Testing message hashing...")
    
    # Create test messages
    messages1 = [
        SystemMessage(content="You are a helpful assistant."),
        UserMessage(content="Hello, how are you?")
    ]
    
    messages2 = [
        SystemMessage(content="You are a helpful assistant."),
        UserMessage(content="Hello, how are you?")
    ]
    
    messages3 = [
        SystemMessage(content="You are a helpful assistant."),
        UserMessage(content="Hello, how are you today?")  # Different content
    ]
    
    # Test hash consistency
    hash1 = hash_messages(messages1)
    hash2 = hash_messages(messages2)
    hash3 = hash_messages(messages3)
    
    assert hash1 == hash2, "Same messages should produce same hash"
    assert hash1 != hash3, "Different messages should produce different hashes"
    assert len(hash1) == 64, "SHA-256 hash should be 64 characters"
    
    print(f"‚úÖ Hash consistency test passed")
    print(f"   Hash 1: {hash1[:16]}...")
    print(f"   Hash 2: {hash2[:16]}...")
    print(f"   Hash 3: {hash3[:16]}...")


def test_agent_output_serialization():
    """Test AgentOutput serialization and deserialization."""
    print("\nüß™ Testing AgentOutput serialization...")

    # For testing purposes, we'll create a simple mock action model
    # that mimics the structure but doesn't require the full registry setup
    from pydantic import create_model
    from browser_use.controller.views import DoneAction

    # Create a test action model with a done field
    TestActionModel = create_model(
        'TestActionModel',
        __base__=ActionModel,
        done=(DoneAction | None, None)
    )

    # Create a mock action using the proper structure
    action = TestActionModel(done=DoneAction(success=True, text='Task completed'))

    # Create test AgentOutput
    original_output = AgentOutput(
        thinking="I need to complete this task",
        evaluation_previous_goal="Previous goal was successful",
        memory="User wants to test functionality",
        next_goal="Complete the test",
        action=[action]
    )
    
    # Test serialization
    serialized = serialize_agent_output(original_output)
    assert isinstance(serialized, dict), "Serialized output should be a dictionary"
    assert 'thinking' in serialized, "Serialized output should contain thinking"
    assert 'action' in serialized, "Serialized output should contain action"
    
    # Test deserialization
    deserialized = deserialize_agent_output(serialized, ActionModel)
    assert isinstance(deserialized, AgentOutput), "Deserialized should be AgentOutput"
    assert deserialized.thinking == original_output.thinking, "Thinking should match"
    assert deserialized.memory == original_output.memory, "Memory should match"
    assert len(deserialized.action) == len(original_output.action), "Action count should match"
    
    print("‚úÖ AgentOutput serialization test passed")


def test_cache_operations():
    """Test cache storage and retrieval operations."""
    print("\nüß™ Testing cache operations...")

    # Create temporary cache directory
    with tempfile.TemporaryDirectory() as temp_dir:
        cache = LLMResponseCache(cache_dir=temp_dir)

        # Import the DoneAction to create a proper action
        from browser_use.controller.views import DoneAction

        # Create test data
        test_hash = "test_hash_123"
        action_data = {'done': DoneAction(success=True, text='Test action')}
        action = ActionModel(**action_data)

        test_output = AgentOutput(
            thinking="Test thinking",
            evaluation_previous_goal="Test evaluation",
            memory="Test memory",
            next_goal="Test goal",
            action=[action]
        )
        
        # Test cache miss
        result = cache.get(test_hash)
        assert result is None, "Cache should be empty initially"
        
        # Test cache set
        cache.set(test_hash, test_output)
        
        # Test cache hit
        cached_data = cache.get(test_hash)
        assert cached_data is not None, "Cache should return stored data"
        assert isinstance(cached_data, dict), "Cached data should be a dictionary"
        
        # Test deserialization of cached data
        deserialized = deserialize_agent_output(cached_data, ActionModel)
        assert deserialized.thinking == test_output.thinking, "Cached thinking should match"
        
        # Test cache stats
        stats = cache.stats()
        assert stats['size'] > 0, "Cache should have items"
        
        print("‚úÖ Cache operations test passed")
        print(f"   Cache stats: {stats}")


async def test_integration_with_mock_llm():
    """Test integration with a mock LLM to verify caching behavior."""
    print("\nüß™ Testing integration with mock LLM...")
    
    # This is a simplified test since we can't easily create a full Agent instance
    # We'll test the core caching logic
    
    from browser_use.agent.cache_utils import LLMResponseCache, hash_messages
    
    # Create temporary cache
    with tempfile.TemporaryDirectory() as temp_dir:
        cache = LLMResponseCache(cache_dir=temp_dir)
        
        # Create test messages
        messages = [
            SystemMessage(content="You are a test assistant."),
            UserMessage(content="Perform a test action.")
        ]
        
        # Generate hash
        messages_hash = hash_messages(messages)
        
        # Simulate first call (cache miss)
        cached_response = cache.get(messages_hash)
        assert cached_response is None, "First call should be cache miss"
        
        # Import the DoneAction to create a proper action
        from browser_use.controller.views import DoneAction

        # Create mock response
        action_data = {'done': DoneAction(success=True, text='Test completed')}
        action = ActionModel(**action_data)

        mock_response = AgentOutput(
            thinking="Processing test request",
            evaluation_previous_goal="No previous goal",
            memory="Test scenario",
            next_goal="Complete test",
            action=[action]
        )
        
        # Cache the response
        cache.set(messages_hash, mock_response)
        
        # Simulate second call (cache hit)
        cached_response = cache.get(messages_hash)
        assert cached_response is not None, "Second call should be cache hit"
        
        # Verify cached response can be deserialized
        deserialized = deserialize_agent_output(cached_response, ActionModel)
        assert deserialized.thinking == mock_response.thinking, "Cached response should match original"
        
        print("‚úÖ Integration test passed")
        print(f"   Messages hash: {messages_hash[:16]}...")
        print(f"   Cache hit successful: {cached_response is not None}")


def main():
    """Run all tests."""
    print("üöÄ Starting LLM caching tests...\n")
    
    try:
        # Run synchronous tests
        test_message_hashing()
        test_agent_output_serialization()
        test_cache_operations()
        
        # Run async test
        asyncio.run(test_integration_with_mock_llm())
        
        print("\nüéâ All tests passed! LLM caching implementation is working correctly.")
        
    except Exception as e:
        print(f"\n‚ùå Test failed: {e}")
        raise


if __name__ == "__main__":
    main()
